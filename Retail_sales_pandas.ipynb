{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd9c0893-158a-4c0a-be1d-ea2a52a3f992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "retailsales_df= pd.read_csv(\"/Volumes/classwork_catalog/classwork_schema/classwork_volume/retail_sales.csv\")\n",
    "print (retailsales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cce673d9-071d-4af5-a29d-f8cdc11c3047",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print (\"rows\",retailsales_df.shape[0])\n",
    "print (\"columns\",retailsales_df.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69f8d681-6ad9-4446-8793-ff55ac9fc8ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retailsales_df.columns=(retailsales_df.columns.str.lower())\n",
    "print(retailsales_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a11c8ac-a82f-48c5-ba41-ec6c4ca73734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retailsales_df.columns=(retailsales_df.columns.str.replace(\" \",\"_\"))\n",
    "print(retailsales_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42652be3-5b6f-4cd7-b49d-b6419ca8d72c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert order date to datetime\n",
    "retailsales_df['order_date'] = pd.to_datetime(retailsales_df['order_date'], errors='coerce')\n",
    "print(retailsales_df.order_date)\n",
    "\n",
    "# Convert numeric columns\n",
    "numeric_cols = ['quantity', 'unit_price', 'discount']\n",
    "print(numeric_cols)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    retailsales_df[col] = pd.to_numeric(retailsales_df[col], errors='coerce')\n",
    "\n",
    "# Fill missing discount\n",
    "retailsales_df['discount'] = retailsales_df['discount'].fillna(0)\n",
    "print(retailsales_df.discount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85183d92-f7a4-4ee4-8b96-93733187acdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Data cleaning \n",
    "\n",
    "remove records where quantity is less than or equal to 0 \n",
    "\n",
    "remove records where unit price is less than or equal to 0 \n",
    "\n",
    "remove records where order date is missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdfb3391-1d45-4aab-ad6c-b3eea8de14f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retailsales_df = retailsales_df[\n",
    "    (retailsales_df['quantity'] >= 0) &\n",
    "    (retailsales_df['unit_price'] >= 0) &\n",
    "    (retailsales_df['order_date'].notna())\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "011125f5-4011-4b56-a3c2-5cf8e7ec8345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create new columns \n",
    "\n",
    "gross_amount = quantity * unit_price \n",
    "\n",
    "net_amount = gross_amount - discount \n",
    "\n",
    "if net_amount is negative, set it to 0 \n",
    "\n",
    "create order_month from order date in YYYY-MM format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abf8744e-69c6-4274-be7c-eff284180435",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Gross Amount\n",
    "retailsales_df['gross_amount'] = retailsales_df['quantity'] * retailsales_df['unit_price']\n",
    "print(retailsales_df.gross_amount)\n",
    "\n",
    "# Net Amount\n",
    "retailsales_df['net_amount'] = retailsales_df['gross_amount'] - retailsales_df['discount']\n",
    "print(retailsales_df.net_amount)\n",
    "\n",
    "# Prevent negative values\n",
    "retailsales_df['net_amount'] = retailsales_df['net_amount'].clip(lower=0)\n",
    "print(retailsales_df.net_amount)\n",
    "\n",
    "# Order Month (YYYY-MM)\n",
    "retailsales_df['order_month'] = retailsales_df['order_date'].dt.strftime('%Y-%m')\n",
    "print(retailsales_df.order_month)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "819fc18e-137a-4894-8920-fcee0616559e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create a final DataFrame called retail_curated_df with only the following columns: \n",
    "\n",
    "order_id \n",
    "\n",
    "order_date \n",
    "\n",
    "order_month \n",
    "\n",
    "customer_id \n",
    "\n",
    "product_id \n",
    "\n",
    "quantity \n",
    "\n",
    "unit_price \n",
    "\n",
    "discount \n",
    "\n",
    "gross_amount \n",
    "\n",
    "net_amount \n",
    "\n",
    "Ensure there are no duplicate records for the same order and product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74cb82de-f0df-49ea-b064-77e7b4d6e46f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retail_finaldataframe_df = retailsales_df[\n",
    "    [\n",
    "        'order_id',\n",
    "        'order_date',\n",
    "        'order_month',\n",
    "        'customer_id',\n",
    "        'product_id',\n",
    "        'quantity',\n",
    "        'unit_price',\n",
    "        'discount',\n",
    "        'gross_amount',\n",
    "        'net_amount'\n",
    "    ]\n",
    "]\n",
    "print(retail_finaldataframe_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7926fac6-8e48-4606-bec2-77a90c1d5f77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4) Load \n",
    "\n",
    "Load the final DataFrame into a table named: \n",
    "\n",
    "analytics.retail_sales_curated \n",
    "\n",
    "(If using Databricks, convert the Pandas DataFrame to Spark and save it as a table.) \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97f902b4-d0f9-4de3-8f61-c1700c2581fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retailsales_finaldataframe_df = retailsales_df.drop_duplicates(\n",
    "    subset=['order_id', 'product_id']\n",
    ")\n",
    "\n",
    "print(\"Final Rows:\", retailsales_finaldataframe_df.shape[0])\n",
    "print(\"Final Columns:\", retailsales_finaldataframe_df.shape[1])\n",
    "\n",
    "retailsales_finaldataframe_df.head()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Retail_sales_pandas",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
